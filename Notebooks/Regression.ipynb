{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Régression Linéaire Multiple : Version Matricielle\n",
    "\n",
    "## 1. Modèle mathématique (notation matricielle)\n",
    "\n",
    "La régression linéaire multiple s'écrit en notation matricielle :\n",
    "\\[\n",
    "\\mathbf{y} = \\mathbf{X} \\cdot \\mathbf{w} + \\mathbf{b}\n",
    "\\]\n",
    "\n",
    "### Définition des termes :\n",
    "- \\( \\mathbf{X} \\) : Matrice \\( m \\times n \\), représentant les données d'entrée (\\( m \\) échantillons, \\( n \\) variables indépendantes).\n",
    "- \\( \\mathbf{w} \\) : Vecteur colonne \\( n \\times 1 \\), contenant les poids ou coefficients (\\( w_1, w_2, \\dots, w_n \\)).\n",
    "- \\( \\mathbf{b} \\) : Scalaire (ou vecteur \\( m \\times 1 \\)), représentant le biais.\n",
    "- \\( \\mathbf{y} \\) : Vecteur \\( m \\times 1 \\), contenant les valeurs cibles.\n",
    "\n",
    "---\n",
    "\n",
    "## 2. Fonction de coût : Erreur quadratique moyenne (MSE)\n",
    "\n",
    "La fonction de coût mesure l'écart entre les prédictions \\( \\hat{\\mathbf{y}} \\) et les valeurs réelles \\( \\mathbf{y} \\). Elle est définie comme :\n",
    "\\[\n",
    "J(\\mathbf{w}, \\mathbf{b}) = \\frac{1}{2m} \\| \\mathbf{X} \\cdot \\mathbf{w} + \\mathbf{b} - \\mathbf{y} \\|^2\n",
    "\\]\n",
    "\n",
    "### Développement :\n",
    "\\[\n",
    "J(\\mathbf{w}, \\mathbf{b}) = \\frac{1}{2m} \\left( (\\mathbf{X} \\cdot \\mathbf{w} + \\mathbf{b} - \\mathbf{y})^\\top \\cdot (\\mathbf{X} \\cdot \\mathbf{w} + \\mathbf{b} - \\mathbf{y}) \\right)\n",
    "\\]\n",
    "\n",
    "---\n",
    "\n",
    "## 3. Descente de gradient\n",
    "\n",
    "La descente de gradient ajuste les paramètres \\( \\mathbf{w} \\) et \\( \\mathbf{b} \\) pour minimiser la fonction de coût \\( J \\).\n",
    "\n",
    "### Mise à jour des poids (\\( \\mathbf{w} \\)) :\n",
    "\\[\n",
    "\\mathbf{w} = \\mathbf{w} - \\alpha \\cdot \\frac{\\partial J}{\\partial \\mathbf{w}}\n",
    "\\]\n",
    "\n",
    "### Mise à jour du biais (\\( \\mathbf{b} \\)) :\n",
    "\\[\n",
    "\\mathbf{b} = \\mathbf{b} - \\alpha \\cdot \\frac{\\partial J}{\\partial \\mathbf{b}}\n",
    "\\]\n",
    "\n",
    "où \\( \\alpha \\) est le taux d'apprentissage.\n",
    "\n",
    "---\n",
    "\n",
    "## 4. Calcul des gradients\n",
    "\n",
    "### Gradient par rapport aux poids (\\( \\mathbf{w} \\)) :\n",
    "\\[\n",
    "\\frac{\\partial J}{\\partial \\mathbf{w}} = \\frac{1}{m} \\cdot \\mathbf{X}^\\top \\cdot \\left( \\mathbf{X} \\cdot \\mathbf{w} + \\mathbf{b} - \\mathbf{y} \\right)\n",
    "\\]\n",
    "\n",
    "### Gradient par rapport au biais (\\( \\mathbf{b} \\)) :\n",
    "Si \\( \\mathbf{b} \\) est constant pour tous les échantillons :\n",
    "\\[\n",
    "\\frac{\\partial J}{\\partial \\mathbf{b}} = \\frac{1}{m} \\cdot \\sum \\left( \\mathbf{X} \\cdot \\mathbf{w} + \\mathbf{b} - \\mathbf{y} \\right)\n",
    "\\]\n",
    "\n",
    "---\n",
    "\n",
    "## 5. Résolution analytique (formule fermée)\n",
    "\n",
    "La minimisation de \\( J \\) peut également être résolue analytiquement avec la **formule normale** :\n",
    "\\[\n",
    "\\mathbf{w} = \\left( \\mathbf{X}^\\top \\mathbf{X} \\right)^{-1} \\cdot \\mathbf{X}^\\top \\cdot \\mathbf{y}\n",
    "\\]\n",
    "\n",
    "### Ajout du biais :\n",
    "Pour inclure \\( \\mathbf{b} \\) dans \\( \\mathbf{w} \\), on peut ajouter une colonne de \\( 1 \\) à la matrice \\( \\mathbf{X} \\).\n",
    "\n",
    "---\n",
    "\n",
    "## 6. Interprétation des coefficients\n",
    "\n",
    "- Chaque coefficient \\( w_j \\) dans \\( \\mathbf{w} \\) représente l'effet marginal de \\( x_j \\) sur \\( y \\), toutes les autres variables étant constantes.\n",
    "- Le biais \\( b \\) est l'interception du modèle, c'est-à-dire la valeur prédite de \\( y \\) lorsque toutes les variables \\( x_1, x_2, \\dots, x_n \\) valent zéro.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
